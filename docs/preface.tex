\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}
\sloppy

This document has been derived from the DNS/CHEM document, originally created at the Computational Fluid Dynamics Laboratory at UC San Diego between 1999 and 2004 ({\tt http://www.cfdlab.ucsd.edu/}). The work has been resumed at the Max Planck Institute for Meteorology since 2010 within the research group Turbulent Mixing Processes in the Earth System ({\tt http://www.mpimet.mpg.de/}).

This manual is simply an introduction to the methodology and code, just a small part of the documentation of the set of tools TLab. The major part of the documentation is in the code itself in terms of {\tt README} files, git version control system and comments within the source files. A set of examples has also been included for the user to get acquainted with the different tools (pre-processing, simulation and post-processing). Please note that, by default, all the different tools are continuously under development, so this document is continuously incomplete -- the comments within the source files have always priority.

TLab---an acronym for Turbulence Laboratory---is a set of tools whose aim is {\bf to efficiently solve and analyze a particular set of governing equations with a controlled accuracy}. The accuracy can be controlled in different ways: comparing with analytical solutions, including linear stability analysis; grid convergence studies; balance of transport equations, like integral turbulent kinetic energy or local values at specific relevant locations (e.g., at the wall). Resolution can be measured by the ratio between the grid spacing $\Delta x$ and the relevant small scales, like the Kolmogorov scale $\eta$ or the thickness of the diffusion sub-layers next to the wall. For the compact schemes used here, typical values are $\Delta x/\eta\simeq 1-2$; larger values can lead to numerical instability because of the aliasing generated by the non-linear terms. Note that these schemes are non-monotone, but typical out-of-bounds deviations of conserved scalars are below $10^{-6}-10^{-8}$ relative to the mean variations, and this error is therefore negligibly small compared to the typical error associated with the statistical convergence, of the order of $1-5$\%. The statistical convergence can be estimated by varying the sample size of the data set, e.g. varying the domain size along the statistically homogeneous directions. The efficiency can be measured in different ways but, ultimate, it should be related with the computational time needed to understand a particular problem with a given accuracy, and so the importance of the controlled accuracy. Making the code user-friendly comes after the previous two main priorities: controlled accuracy and efficiency.

Regarding the content of this document, the first chapter describes the mathematical formulation, in particular, the governing equations. The boundary and initial conditions, discussed in chapter~\ref{sec:bcs}, are relatively simple for the geometries that we use; the major complexity is its actual implementation. Chapter~\ref{sec:code} covers the code structure itself and the input data, the grid being discussed separately in chapter~\ref{sec:grid}, and the postprocessing tools in chapter~\ref{sec:postprocessing}. As already mentioned, this part should be complemented with the examples included in the directory. Chapter~\ref{sec:numerics} cover some major aspects of the numerical algorithms; details thereof, however, are to be found in the papers that are referred to in that part. The parallelization is discussed in chapter~\ref{sec:mpi}. So far, this includes only the domain decomposition. Last, scaling studies are included in chapter~\ref{sec:scaling}.
